{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_stock_data(data_dir, stock_name, output_dir, resample_periods=[\"1min\", \"5min\", \"15min\", \"30min\", \"60min\"]):\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        txt_files = [f for f in files if f.endswith('.txt')]\n",
    "        for file in txt_files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, delimiter=\",\")\n",
    "                df.columns = df.columns.str.strip()\n",
    "\n",
    "                required_cols = [\n",
    "                    \"Date\", \"Time\", \"Last_Tick_Price\",\n",
    "                    \"Total_Shares_Volume\", \"Total_Monetary_Volume\", \"Trade_Count\"\n",
    "                ]\n",
    "                if not all(col in df.columns for col in required_cols):\n",
    "                    print(f\"跳过文件 {file}，缺少关键列: {set(required_cols) - set(df.columns)}\")\n",
    "                    continue\n",
    "\n",
    "                df[\"Date\"] = df[\"Date\"].astype(str)\n",
    "                df[\"Time\"] = df[\"Time\"].astype(int)\n",
    "                df[\"Time\"] = pd.to_timedelta(df[\"Time\"], unit=\"s\")\n",
    "                df[\"Datetime\"] = pd.to_datetime(df[\"Date\"], format=\"%Y%m%d\") + df[\"Time\"]\n",
    "                df = df.set_index(\"Datetime\")\n",
    "                df_all = pd.concat([df_all, df])\n",
    "            except Exception as e:\n",
    "                print(f\"处理文件 {file} 时出错：{e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"\\n {stock_name}：共合并 {len(df_all)} 条原始记录\")\n",
    "\n",
    "    df_all = df_all[\n",
    "        (df_all[\"Last_Tick_Price\"] > 0) &\n",
    "        (df_all[\"Total_Shares_Volume\"] > 0) &\n",
    "        (df_all[\"Total_Monetary_Volume\"] > 0) &\n",
    "        (df_all[\"Trade_Count\"] > 0)\n",
    "    ]\n",
    "    df_all = df_all.sort_index().dropna()\n",
    "\n",
    "    for period in resample_periods:\n",
    "        df_resampled = df_all.resample(period).agg({\n",
    "            \"Last_Tick_Price\": \"last\",\n",
    "            \"Average_Price\": \"mean\",\n",
    "            \"Median_Price\": \"mean\",\n",
    "            \"Average_Log_Price\": \"mean\",\n",
    "            \"Total_Shares_Volume\": \"sum\",\n",
    "            \"Total_Monetary_Volume\": \"sum\",\n",
    "            \"Trade_Count\": \"sum\",\n",
    "            \"Volume_Weighted_Average_Price\": \"mean\"\n",
    "        })\n",
    "\n",
    "        df_resampled.columns = [\n",
    "            \"ClosePrice\", \"AvgPrice\", \"MedianPrice\", \"LogAvgPrice\",\n",
    "            \"TotalVolume\", \"TotalAmount\", \"TradeCount\", \"VWAP\"\n",
    "        ]\n",
    "\n",
    "        df_resampled[\"FutureDirection\"] = (df_resampled[\"ClosePrice\"].shift(-1) > df_resampled[\"ClosePrice\"]).astype(int)\n",
    "        df_resampled = df_resampled.dropna()\n",
    "\n",
    "        print(f\"\\n {stock_name} - {period} 样本数：{len(df_resampled)}\")\n",
    "        print(df_resampled[\"FutureDirection\"].value_counts())\n",
    "        print(df_resampled[\"FutureDirection\"].value_counts(normalize=True))\n",
    "\n",
    "        # 保存\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"{stock_name}_resampled_{period}_with_labels.csv\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        df_resampled.to_csv(output_path)\n",
    "        print(f\" 保存成功：{output_path}\")\n",
    "\n",
    "#  要处理的文件夹和股票名\n",
    "stock_dirs = {\n",
    "    \"GE\":  \"D:\\\\zangyujiao\\\\Desktop\\\\data\\\\GE\",\n",
    "    \"IBM\": \"D:\\\\zangyujiao\\\\Desktop\\\\data\\\\IBM\",\n",
    "    \"JPM\": \"D:\\\\zangyujiao\\\\Desktop\\\\data\\\\JPM\",\n",
    "    \"PFE\": \"D:\\\\zangyujiao\\\\Desktop\\\\data\\\\PFE\",\n",
    "    \"PG\":  \"D:\\\\zangyujiao\\\\Desktop\\\\data\\\\PG\"\n",
    "}\n",
    "\n",
    "#  指定统一输出目录\n",
    "output_base = \"D:\\\\zangyujiao\\\\Desktop\\\\resampled_output\"\n",
    "\n",
    "#  执行处理\n",
    "for stock_name, folder in stock_dirs.items():\n",
    "    output_dir = os.path.join(output_base, stock_name)\n",
    "    process_stock_data(folder, stock_name, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 读取CSV数据\n",
    "file_path = r\"D:\\zangyujiao\\Desktop\\resampled_output\\GE\\GE_resampled_1min_with_labels.csv\"\n",
    "df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "\n",
    "# 删除缺失High/Low因子部分\n",
    "windows = [3, 5, 10, 20]\n",
    "for window in windows:\n",
    "    df[f\"momentum_{window}\"] = df[\"ClosePrice\"] / df[\"ClosePrice\"].shift(window) - 1\n",
    "    df[f\"cum_ret_{window}\"] = np.log(df[\"ClosePrice\"]).diff().rolling(window).sum()\n",
    "    df[f\"bias_{window}\"] = df[\"ClosePrice\"] / df[\"ClosePrice\"].rolling(window).mean() - 1\n",
    "    df[f\"vol_mom_{window}\"] = df[\"TotalVolume\"] / df[\"TotalVolume\"].shift(window) - 1\n",
    "    df[f\"amt_mom_{window}\"] = df[\"TotalAmount\"] / df[\"TotalAmount\"].shift(window) - 1\n",
    "    df[f\"tradecount_mom_{window}\"] = df[\"TradeCount\"] / df[\"TradeCount\"].shift(window) - 1\n",
    "    df[f\"volatility_{window}\"] = df[\"ClosePrice\"].pct_change().rolling(window).std()\n",
    "\n",
    "# 组合因子\n",
    "df[\"price_vol_combo\"] = df[\"momentum_5\"] * df[\"vol_mom_5\"]\n",
    "df[\"vol_price_divergence\"] = df[\"vol_mom_5\"] - df[\"momentum_5\"]\n",
    "df[\"mom_diff\"] = df[\"momentum_20\"] - df[\"momentum_5\"]\n",
    "\n",
    "# 去除NA\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 因子列名\n",
    "factor_cols = [col for col in df.columns if any(k in col for k in [\n",
    "    \"momentum\", \"bias\", \"ret\", \"vol_\", \"amt_\", \"tradecount\", \"combo\", \"diff\"])]\n",
    "\n",
    "# 分训练集和测试集\n",
    "split_index = int(len(df) * 0.7)\n",
    "df_train = df.iloc[:split_index]\n",
    "df_test = df.iloc[split_index:]\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(df_train[factor_cols]), columns=factor_cols, index=df_train.index)\n",
    "X_test = pd.DataFrame(scaler.transform(df_test[factor_cols]), columns=factor_cols, index=df_test.index)\n",
    "\n",
    "# 标签\n",
    "y_train = df_train[\"FutureDirection\"]\n",
    "y_test = df_test[\"FutureDirection\"]\n",
    "\n",
    "# 计算IC值\n",
    "ic_values = {}\n",
    "for col in factor_cols:\n",
    "    ic = stats.spearmanr(X_test[col], y_test)[0]\n",
    "    ic_values[col] = ic\n",
    "\n",
    "# 可视化：IC条形图\n",
    "plt.figure(figsize=(12, 6))\n",
    "sorted_ic = dict(sorted(ic_values.items(), key=lambda item: abs(item[1]), reverse=True))\n",
    "sns.barplot(x=list(sorted_ic.keys()), y=list(sorted_ic.values()))\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Information Coefficient (IC) for Factors\")\n",
    "plt.ylabel(\"Spearman IC\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 分组收益分析（Top 3因子）\n",
    "top3_factors = list(sorted_ic.keys())[:3]\n",
    "group_returns = {}\n",
    "\n",
    "for factor in top3_factors:\n",
    "    df_test[\"factor_quantile\"] = pd.qcut(X_test[factor], q=5, labels=False)\n",
    "    group_ret = df_test.groupby(\"factor_quantile\")[\"FutureDirection\"].mean()\n",
    "    group_returns[factor] = group_ret\n",
    "\n",
    "# 绘图\n",
    "for factor, ret in group_returns.items():\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(x=ret.index.astype(str), y=ret.values)\n",
    "    plt.title(f\"Future Up Probability by Factor Quantile: {factor}\")\n",
    "    plt.xlabel(\"Quantile (0=Lowest, 4=Highest)\")\n",
    "    plt.ylabel(\"Mean FutureDirection\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 建立模型\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # 预测为上涨的概率\n",
    "\n",
    "# 模型评估指标\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\" 多因子模型性能评估：\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 可视化：特征系数重要性\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Factor\": X_train.columns,\n",
    "    \"Coefficient\": model.coef_[0]\n",
    "}).sort_values(by=\"Coefficient\", key=abs, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Factor\", data=coef_df)\n",
    "plt.title(\"Logistic Regression Coefficient Importance\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 加载数据\n",
    "file_path = r\"D:\\zangyujiao\\Desktop\\resampled_output\\GE\\GE_resampled_1min_with_labels.csv\"\n",
    "df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "\n",
    "# 构造动量类因子\n",
    "windows = [3, 5, 10, 20]\n",
    "for window in windows:\n",
    "    df[f\"momentum_{window}\"] = df[\"ClosePrice\"] / df[\"ClosePrice\"].shift(window) - 1\n",
    "    df[f\"cum_ret_{window}\"] = np.log(df[\"ClosePrice\"]).diff().rolling(window).sum()\n",
    "    df[f\"bias_{window}\"] = df[\"ClosePrice\"] / df[\"ClosePrice\"].rolling(window).mean() - 1\n",
    "    df[f\"vol_mom_{window}\"] = df[\"TotalVolume\"] / df[\"TotalVolume\"].shift(window) - 1\n",
    "    df[f\"amt_mom_{window}\"] = df[\"TotalAmount\"] / df[\"TotalAmount\"].shift(window) - 1\n",
    "    df[f\"tradecount_mom_{window}\"] = df[\"TradeCount\"] / df[\"TradeCount\"].shift(window) - 1\n",
    "    df[f\"volatility_{window}\"] = df[\"ClosePrice\"].pct_change().rolling(window).std()\n",
    "\n",
    "# 构造组合因子\n",
    "df[\"price_vol_combo\"] = df[\"momentum_5\"] * df[\"vol_mom_5\"]\n",
    "df[\"vol_price_divergence\"] = df[\"vol_mom_5\"] - df[\"momentum_5\"]\n",
    "df[\"mom_diff\"] = df[\"momentum_20\"] - df[\"momentum_5\"]\n",
    "\n",
    "# 去除NA\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 收集因子列\n",
    "factor_cols = [col for col in df.columns if any(k in col for k in [\n",
    "    \"momentum\", \"bias\", \"ret\", \"vol_\", \"amt_\", \"tradecount\", \"combo\", \"diff\"])]\n",
    "\n",
    "# 划分训练测试集\n",
    "split_index = int(len(df) * 0.7)\n",
    "df_train = df.iloc[:split_index]\n",
    "df_test = df.iloc[split_index:]\n",
    "\n",
    "X_train = df_train[factor_cols]\n",
    "y_train = df_train[\"FutureDirection\"]\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# LassoCV 模型进行变量选择\n",
    "lasso = LassoCV(cv=5, random_state=42).fit(X_train_scaled, y_train)\n",
    "\n",
    "# 系数结果\n",
    "lasso_coef = pd.Series(lasso.coef_, index=factor_cols)\n",
    "lasso_coef_filtered = lasso_coef[lasso_coef != 0]\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(10, 6))\n",
    "lasso_coef_filtered.sort_values().plot(kind='barh')\n",
    "plt.title(\"LassoCV Selected Factor Coefficients\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28997af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 策略函数\n",
    "def run_strategy_on_file(file_path, plot=True):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "\n",
    "        windows = [3, 5, 10, 20]\n",
    "        for window in windows:\n",
    "            df[f\"momentum_{window}\"] = df[\"ClosePrice\"] / df[\"ClosePrice\"].shift(window) - 1\n",
    "            df[f\"bias_{window}\"] = df[\"ClosePrice\"] / df[\"ClosePrice\"].rolling(window).mean() - 1\n",
    "            df[f\"vol_mom_{window}\"] = df[\"TotalVolume\"] / df[\"TotalVolume\"].shift(window) - 1\n",
    "\n",
    "        df[\"alpha_score\"] = (\n",
    "            0.4 * df[\"momentum_5\"].fillna(0) +\n",
    "            0.3 * df[\"bias_10\"].fillna(0) +\n",
    "            0.3 * df[\"vol_mom_10\"].fillna(0)\n",
    "        )\n",
    "\n",
    "        df[\"signal\"] = 0\n",
    "        df.loc[df[\"alpha_score\"] > df[\"alpha_score\"].quantile(0.8), \"signal\"] = 1\n",
    "        df.loc[df[\"alpha_score\"] < df[\"alpha_score\"].quantile(0.2), \"signal\"] = -1\n",
    "\n",
    "        df[\"strategy_return\"] = df[\"signal\"].shift(1) * df[\"ClosePrice\"].pct_change()\n",
    "        df[\"cumulative_strategy_return\"] = (1 + df[\"strategy_return\"]).cumprod()\n",
    "        df[\"buy_and_hold\"] = (1 + df[\"ClosePrice\"].pct_change()).cumprod()\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(df[\"cumulative_strategy_return\"], label=\"Strategy\")\n",
    "            plt.plot(df[\"buy_and_hold\"], label=\"Buy & Hold\", linestyle='--')\n",
    "            plt.title(f\"Strategy vs Buy & Hold\\n{os.path.basename(file_path)}\")\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Cumulative Return\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" 文件 {file_path} 处理失败：{e}\")\n",
    "        return None\n",
    "# 指定文件夹路径（根目录）\n",
    "root_dir = r\"D:\\zangyujiao\\Desktop\\resampled_output\"\n",
    "\n",
    "# 遍历所有子目录下的CSV文件\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\") and \"with_labels\" in file:\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"\\n 正在处理：{file_path}\")\n",
    "            _ = run_strategy_on_file(file_path, plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d48ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
